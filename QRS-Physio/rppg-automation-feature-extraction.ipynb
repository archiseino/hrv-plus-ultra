{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Store the RPPG Result and the Graph of the Subject folders\n",
    "\n",
    "Will store the RPPG signal (raw) and then the pre-processed one (v0.1) and the image comparasion between the GT -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dependencies\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=\"../Models/blaze_face_short_range.tflite\"\n",
    "# base_model=\"../Models/face_landmarker.task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Define the POS method\n",
    "Pos Method by Wenjin Wang -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Core method POS \n",
    "# def POS(signal, **kargs):\n",
    "#     \"\"\"\n",
    "#     POS method on CPU using Numpy.\n",
    "\n",
    "#     The dictionary parameters are: {'fps':float}.\n",
    "\n",
    "#     Wang, W., den Brinker, A. C., Stuijk, S., & de Haan, G. (2016). Algorithmic principles of remote PPG. IEEE Transactions on Biomedical Engineering, 64(7), 1479-1491. \n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     eps: A small constant (10^-9) used to prevent division by zero in normalization steps.\n",
    "#     X: The input signal, which is a 3D array where:\n",
    "#     e: Number of estimators or regions in the frame (like different parts of the face).\n",
    "#     c: Color channels (3 for RGB).\n",
    "#     f: Number of frames.\n",
    "#     w: Window length, determined by the camera's frame rate (fps). For example, at 20 fps, w would be 32 (which corresponds to about 1.6 seconds of video).\n",
    "#     \"\"\"\n",
    "#     eps = 10**-9\n",
    "#     X = signal\n",
    "#     e, c, f = X.shape # Number of estimators, color channels, and frames\n",
    "#     w = int(1.6 * kargs['fps']) # Window length in frames\n",
    "\n",
    "#     \"\"\"\n",
    "#     P: A fixed 2x3 matrix used for the projection step. It defines how to transform the color channels (RGB) into a new space.\n",
    "#     Q: This is a stack of the matrix P repeated e times, where each P corresponds to an estimator (region of interest) in the video.\n",
    "#     \"\"\"\n",
    "#     P = np.array([[0, 1, -1], [-2, 1, 1]]) ## Pulse Rate Matricies\n",
    "#     Q = np.stack([P for _ in range(e)], axis = 0)\n",
    "\n",
    "#     \"\"\"\n",
    "#     H: A matrix to store the estimated heart rate signal over time for each estimator.\n",
    "#     n: The current frame in the sliding window.\n",
    "#     m: The start index of the sliding window (calculating which frames are part of the current window).\n",
    "#     \"\"\"\n",
    "#     H = np.zeros((e, f))\n",
    "#     for n in np.arange(w, f):\n",
    "#         # Start index of sliding window \n",
    "#         m = n - w + 1\n",
    "\n",
    "#         \"\"\"\n",
    "#         Temporal Normalization (Equation 5 from the paper): This step ensures that the signal is invariant to global lighting changes and other noise factors.\n",
    "#         \"\"\"\n",
    "#         Cn = X[:, :, m:(n+1)]\n",
    "#         M = 1.0 / (np.mean(Cn, axis = 2) + eps)\n",
    "#         M = np.expand_dims(M, axis=2) # shape [e, c, w]\n",
    "#         Cn = np.multiply(Cn, M)\n",
    "\n",
    "#         \"\"\"\n",
    "#         Projection (Equation 6 from the paper): This step transforms the RGB values into a space where the signal from blood flow (heart rate) is more distinct.\n",
    "#         \"\"\"\n",
    "#         S = np.dot(Q, Cn)\n",
    "#         S = S[0, :, :, :]\n",
    "#         S = np.swapaxes(S, 0, 1) \n",
    "\n",
    "#         \"\"\"\n",
    "#         Tuning (Equation 7 from the paper): This step adjusts the projected components to make the heart rate signal clearer.\n",
    "#         \"\"\"\n",
    "#         S1 = S[:, 0, :]\n",
    "#         S2 = S[:, 1, :]\n",
    "#         alpha = np.std(S1, axis=1) / (eps + np.std(S2, axis=1))\n",
    "#         alpha - np.expand_dims(alpha, axis=1)\n",
    "#         Hn = np.add(S1, alpha * S2)\n",
    "#         Hnm = Hn - np.expand_dims(np.mean(Hn, axis=1), axis=1)\n",
    "\n",
    "#         \"\"\"\n",
    "#         Overlap-Adding (Equation 8 from the paper): This step combines the processed signals from each frame to form the final output heart rate signal.\n",
    "#         \"\"\"\n",
    "#         H[:, m:(n + 1)] = np.add(H[:, m:(n + 1)], Hnm)  # Add the tuned signal to the output matrix\n",
    "\n",
    "#     return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Setup Mediapipe ROI Capture\n",
    "\n",
    "Setup the functions and properties for doing the RPPGs -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create faceDetector Object\n",
    "# base_options = python.BaseOptions(model_asset_path=base_model)\n",
    "# FaceDetector = mp.tasks.vision.FaceDetector\n",
    "# FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
    "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "# options = FaceDetectorOptions(\n",
    "#     base_options=base_options,\n",
    "#     running_mode = VisionRunningMode.IMAGE,\n",
    "# )\n",
    "# detector = vision.FaceDetector.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create Facelandmarker Object\n",
    "# base_options = python.BaseOptions(model_asset_path=base_model)\n",
    "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "# options = vision.FaceLandmarkerOptions(\n",
    "#     base_options=base_options,\n",
    "#     num_faces=1,\n",
    "#     running_mode = VisionRunningMode.IMAGE,\n",
    "# )\n",
    "# detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cheek_rois(landmarks, image_shape):\n",
    "#     h, w, _ = image_shape\n",
    "#     left_cheek_indices = [111, 121, 50, 142]\n",
    "#     right_cheek_indices = [350, 340, 355, 280]\n",
    "\n",
    "#     left_cheek_points = [(int(landmarks[idx].x * w), int(landmarks[idx].y * h)) for idx in left_cheek_indices]\n",
    "#     right_cheek_points = [(int(landmarks[idx].x * w), int(landmarks[idx].y * h)) for idx in right_cheek_indices]\n",
    "\n",
    "#     left_cheek_rect = (\n",
    "#         min([pt[0] for pt in left_cheek_points]), min([pt[1] for pt in left_cheek_points]),\n",
    "#         max([pt[0] for pt in left_cheek_points]), max([pt[1] for pt in left_cheek_points])\n",
    "#     )\n",
    "#     # print(\"Left Cheek Rect:\", left_cheek_rect)\n",
    "#     right_cheek_rect = (\n",
    "#         min([pt[0] for pt in right_cheek_points]), min([pt[1] for pt in right_cheek_points]),\n",
    "#         max([pt[0] for pt in right_cheek_points]), max([pt[1] for pt in right_cheek_points])\n",
    "#     )\n",
    "#     # print(\"Right Cheek Rect:\", right_cheek_rect)\n",
    "\n",
    "#     return left_cheek_rect, right_cheek_rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_rgb_from_rect(rect, image):\n",
    "#     x_min, y_min, x_max, y_max = rect\n",
    "#     roi = image[y_min:y_max, x_min:x_max]\n",
    "#     return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Preprocessing Signal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_ppg(signal, fs = 30):\n",
    "#     \"\"\" Computes the Preprocessed PPG Signal, this steps include the following:\n",
    "#         1. Moving Average Smoothing\n",
    "#         2. Bandpass Filtering\n",
    "        \n",
    "#         Parameters:\n",
    "#         ----------\n",
    "#         signal (numpy array): \n",
    "#             The PPG Signal to be preprocessed\n",
    "#         fs (float): \n",
    "#             The Sampling Frequency of the Signal\n",
    "            \n",
    "#         Returns:\n",
    "#         --------\n",
    "#         numpy array: \n",
    "#             The Preprocessed PPG Signal\n",
    "    \n",
    "#     \"\"\" \n",
    "\n",
    "#     # Moving Average Smoothing\n",
    "#     window = int(fs * 0.15)  # 150ms window\n",
    "#     smoothed_signal = np.convolve(signal, np.ones(window)/window, mode='same')\n",
    "\n",
    "#     b, a = scipy.signal.butter(2, [0.5, 2.5], btype='band', fs=fs)\n",
    "#     filtered = scipy.signal.filtfilt(b, a, smoothed_signal)\n",
    "    \n",
    "#     # Additional lowpass to remove high-frequency noise\n",
    "#     b2, a2 = scipy.signal.butter(3, 2.5, btype='low', fs=fs)\n",
    "#     filtered = scipy.signal.filtfilt(b2, a2, filtered)\n",
    "    \n",
    "#     # Moving average smoothing\n",
    "#     window = int(fs * 0.15)  # 150ms window\n",
    "#     filtered_signal = np.convolve(filtered, np.ones(window)/window, mode='same')\n",
    "\n",
    "#     # Normalize the signal\n",
    "#     normalized_signal = (filtered_signal - np.min(filtered_signal)) / (np.max(filtered_signal) - np.min(filtered_signal))\n",
    "\n",
    "\n",
    "#     return normalized_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## HRV - v0.1\n",
    "\n",
    "Extraction the RGB Signal over the entire frame image -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" RGB Signal Variables\n",
    "\n",
    "#     Variables to store the RGB signals from the left and right cheeks,\n",
    "#     as well as the combined signal from both cheeks.\n",
    "\n",
    "# \"\"\"\n",
    "# ## Utils\n",
    "# fs = 30 # Sampling rate in Hz for RPPG signal\n",
    "\n",
    "\n",
    "# # X should be increasing, y should be decreasing\n",
    "# # w should be decreasing, h should be decreasing to fit the box into the face\n",
    "\n",
    "# # Fixed adjustment values (in pixels)\n",
    "# margin_x = 10  # Adjust horizontally\n",
    "# scaling_factor = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Since the base folders path is around \"datasets/subjects, we will create a target folders processed\n",
    "# \"\"\"\n",
    "# def get_image_roi(folders, image_file):\n",
    "#     target_folders = \"/processed\"\n",
    "#     rgb_folder = folders + \"/rgb\"\n",
    "\n",
    "#     ## create the target folder\n",
    "#     if not os.path.exists(folders + target_folders):\n",
    "#         os.makedirs(folders + target_folders)\n",
    "        \n",
    "#     video_files = sorted(os.listdir(rgb_folder))\n",
    "\n",
    "#     ## Get the first image\n",
    "#     image_path = os.path.join(rgb_folder, video_files[0])\n",
    "#     image = cv2.imread(image_path)\n",
    "\n",
    "#     ## ===========================================\n",
    "    \n",
    "#     ## Get the image_path \n",
    "#     image_path = os.path.join(rgb_folder, video_files[0])\n",
    "#     image = cv2.imread(image_path)\n",
    "\n",
    "#     ## Convert the image to RGB\n",
    "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     mp_image = mp.Image(\n",
    "#         image_format=mp.ImageFormat.SRGB,\n",
    "#         data=image_rgb\n",
    "#     )\n",
    "\n",
    "#     ## Get the landkmarks\n",
    "#     result = detector.detect(mp_image)\n",
    "\n",
    "#     if result.detections:\n",
    "#         print(\"Face Detected\")\n",
    "#         for detection in result.detections:\n",
    "\n",
    "#             # Get the Bounding box\n",
    "#             bboxC = detection.bounding_box\n",
    "#             x, y, w, h = bboxC.origin_x, bboxC.origin_y, bboxC.width, bboxC.height\n",
    "\n",
    "#             new_x = int(x + margin_x)\n",
    "\n",
    "#             new_w = int(w * scaling_factor)\n",
    "#             new_h = int(h * scaling_factor)\n",
    "\n",
    "#             ## Draw the rectangle\n",
    "#             cv2.rectangle(image_rgb, (new_x, y), (new_x + new_w, y + new_h), (0, 255, 0), 2)\n",
    "    \n",
    "#     # if result.face_landmarks:\n",
    "#     #     ## Check if face detected\n",
    "#     #     print(\"Face Detected\")\n",
    "#     #     for face_landmark in result.face_landmarks:\n",
    "#     #         # Get cheek ROIs\n",
    "#     #         left_cheek_rect, right_cheek_rect = get_cheek_rois(face_landmark, image_rgb.shape)\n",
    "\n",
    "#     #         # Extract the RGB signals from the left and right cheeks\n",
    "#     #         left_cheek_roi = extract_rgb_from_rect(left_cheek_rect, image_rgb)\n",
    "#     #         right_cheek_roi = extract_rgb_from_rect(right_cheek_rect, image_rgb)\n",
    "\n",
    "#     #         # print(\"Left Cheek ROI Shape:\", left_cheek_roi.shape)\n",
    "#     #         # print(\"Right Cheek ROI Shape:\", right_cheek_roi.shape)\n",
    "\n",
    "#     #         # Draw both cheek ROIs with rectangles\n",
    "#     #         cv2.rectangle(image_rgb, (left_cheek_rect[0], left_cheek_rect[1]), (left_cheek_rect[2], left_cheek_rect[3]), (0, 255, 0), 2)\n",
    "#     #         cv2.rectangle(image_rgb, (right_cheek_rect[0], right_cheek_rect[1]), (right_cheek_rect[2], right_cheek_rect[3]), (0, 255, 0), 2)\n",
    "            \n",
    "#     #         # Calculate mean pixel values for the RGB channels\n",
    "#     #         left_cheek_rgb = cv2.mean(left_cheek_roi)[:3]\n",
    "#     #         right_cheek_rgb = cv2.mean(right_cheek_roi)[:3]\n",
    "\n",
    "#             ## Print the RGB value\n",
    "#             # print(\"Left Cheek RGB:\", left_cheek_rgb)\n",
    "#             # print(\"Right Cheek RGB:\", right_cheek_rgb)\n",
    "#             # print(\"Combined RGB:\", (combined_r, combined_g, combined_b))\n",
    "\n",
    "#     ## Save the image into the Target Folder\n",
    "#     target_path = os.path.join(folders + target_folders, image_file)\n",
    "#     cv2.imwrite(target_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Saving the RGB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saving_roi_mediapipe(folders, image_file):\n",
    "\n",
    "#     # Lists to store combined RGB values\n",
    "#     combined_r_signal, combined_g_signal, combined_b_signal = [], [], []\n",
    "\n",
    "#     target_folders = \"/processed\"\n",
    "#     rgb_folder = folders + \"/rgb\"\n",
    "\n",
    "#     ## create the target folder\n",
    "#     if not os.path.exists(folders + target_folders):\n",
    "#         os.makedirs(folders + target_folders)\n",
    "\n",
    "#     # Load the video frames\n",
    "#     video_files = sorted(os.listdir(rgb_folder))\n",
    "\n",
    "#     # Load the face landmarks\n",
    "#     for i in range(len(video_files) - 1): ## The last one is\n",
    "#         # Load the image\n",
    "#         image_path = os.path.join(rgb_folder, video_files[i])\n",
    "#         image = cv2.imread(image_path)\n",
    "\n",
    "#         ## Detect the face area using shape\n",
    "#         h, w, _ = image.shape\n",
    "\n",
    "#         ## Converting into RGB\n",
    "#         image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         ## Seting up the Mediapipe Image\n",
    "#         mp_image = mp.Image(\n",
    "#             image_format=mp.ImageFormat.SRGB,\n",
    "#             data=image_rgb\n",
    "#         )\n",
    "\n",
    "#         # ## Get the landkmarks\n",
    "#         result = detector.detect(mp_image)\n",
    "\n",
    "#         if result.detections:\n",
    "#             for detection in result.detections:\n",
    "\n",
    "#                 ## Get the Bounding box\n",
    "#                 bboxC = detection.bounding_box\n",
    "#                 x, y, w, h = bboxC.origin_x, bboxC.origin_y, bboxC.width, bboxC.height\n",
    "\n",
    "#                 new_x = int(x + margin_x)\n",
    "\n",
    "#                 new_w = int(w * scaling_factor)\n",
    "#                 new_h = int(h * scaling_factor)\n",
    "\n",
    "#                 ## Get the ROI\n",
    "#                 face_roi = image_rgb[y:y+new_h, new_x:new_x+new_w]\n",
    "\n",
    "#                 ## Calculate the Mean\n",
    "#                 mean_rgb = cv2.mean(face_roi)[:3]\n",
    "                \n",
    "#                 # Append the combined RGB values to the respective lists\n",
    "#                 combined_r_signal.append(mean_rgb[0])\n",
    "#                 combined_g_signal.append(mean_rgb[1])\n",
    "#                 combined_b_signal.append(mean_rgb[2])\n",
    "\n",
    "#         # Extract the face landmarks\n",
    "#         # if result.face_landmarks:\n",
    "#         #     for face_landmark in result.face_landmarks:\n",
    "#         #         # Get cheek ROIs\n",
    "#         #         left_cheek_rect, right_cheek_rect = get_cheek_rois(face_landmark, image_rgb.shape)\n",
    "\n",
    "#         #         # Draw both cheek ROIs with rectangles\n",
    "#         #         cv2.rectangle(image_rgb, (left_cheek_rect[0], left_cheek_rect[1]), (left_cheek_rect[2], left_cheek_rect[3]), (0, 255, 0), 2)\n",
    "#         #         cv2.rectangle(image_rgb, (right_cheek_rect[0], right_cheek_rect[1]), (right_cheek_rect[2], right_cheek_rect[3]), (0, 255, 0), 2)\n",
    "\n",
    "#         #         # Extract the left and right cheek ROIs\n",
    "#         #         left_cheek_roi = extract_rgb_from_rect(left_cheek_rect, image_rgb)\n",
    "#         #         right_cheek_roi = extract_rgb_from_rect(right_cheek_rect, image_rgb)\n",
    "\n",
    "#         #         # Calculate mean pixel values for the RGB channels\n",
    "#         #         left_cheek_rgb = cv2.mean(left_cheek_roi)[:3]\n",
    "#         #         right_cheek_rgb = cv2.mean(right_cheek_roi)[:3]\n",
    "\n",
    "#         #         # Combine and average the RGB values from both cheeks\n",
    "#         #         combined_r = (left_cheek_rgb[0] + right_cheek_rgb[0]) / 2\n",
    "#         #         combined_g = (left_cheek_rgb[1] + right_cheek_rgb[1]) / 2\n",
    "#         #         combined_b = (left_cheek_rgb[2] + right_cheek_rgb[2]) / 2\n",
    "\n",
    "#         #         # Append the combined RGB values to the respective lists\n",
    "#         #         combined_r_signal.append(combined_r)\n",
    "#         #         combined_g_signal.append(combined_g)\n",
    "#         #         combined_b_signal.append(combined_b)\n",
    "\n",
    "\n",
    "#     ## Plot the RGB path \n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     plt.plot(combined_r_signal, 'r', label='Red')\n",
    "#     plt.plot(combined_g_signal, 'g', label='Green')\n",
    "#     plt.plot(combined_b_signal, 'b', label='Blue')\n",
    "#     plt.title('RGB Signal')\n",
    "#     plt.xlabel('Frame')\n",
    "#     plt.ylabel('Intensity')\n",
    "#     plt.legend()\n",
    "\n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-rgb.png\")\n",
    "#     plt.close()\n",
    "\n",
    "#     ## Calculating the RPPG signal\n",
    "#     rgb_signals = np.array([combined_r_signal, combined_g_signal, combined_b_signal])\n",
    "#     rgb_signals = rgb_signals.reshape(1, 3, -1)\n",
    "#     rppg_signal = POS(rgb_signals, fps=30)\n",
    "#     rppg_signal = rppg_signal.reshape(-1)\n",
    "\n",
    "#     # Show the RPPG Signal\n",
    "#     plt.figure(figsize=(20, 5))\n",
    "#     plt.plot(rppg_signal, color='black')\n",
    "#     plt.title('rPPG Signal')\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-rppg.png\")\n",
    "#     plt.close()\n",
    "\n",
    "#     ## Save the RPPG Signal\n",
    "#     rppg_path = folders + target_folders + f\"/{image_file}-rppg.npy\"\n",
    "#     np.save(rppg_path, rppg_signal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Preprocessed Signals\n",
    "Save the Frequency Domain Pre / Post proccessing Signal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processing_signal(folders, image_file, fs=30):\n",
    "#     target_folders = \"/processed\"\n",
    "    \n",
    "#     if not os.path.exists(folders + target_folders):\n",
    "#         print(\"Subject can't be detected on Mediapipe, skipping\")\n",
    "#         return\n",
    "    \n",
    "#     ## Load the RPPG Signal\n",
    "#     rppg_path = folders + target_folders + f\"/{image_file}-rppg.npy\"\n",
    "#     rppg_signal = np.load(rppg_path)\n",
    "\n",
    "#     ## Compute the Frequency Component (Before)\n",
    "#     # Perform FFT on the RPPG signal\n",
    "#     fft_result = np.fft.fft(rppg_signal)\n",
    "#     fft_freqs = np.fft.fftfreq(len(rppg_signal), d=1/fs)\n",
    "\n",
    "#     # Take the magnitude of the FFT result\n",
    "#     fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "#     # Plot the FFT result\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "#     plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Magnitude')\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-fft-before.png\")\n",
    "#     plt.close()\n",
    "\n",
    "#     ## Doing the preprocessing\n",
    "#     ## Filter RPPG Signal\n",
    "#     preprocessed_signal = preprocess_ppg(rppg_signal, fs=30)\n",
    "\n",
    "#     ## Show the Filtered RPPG Signal\n",
    "#     fig, ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "#     ax[0].plot(rppg_signal, color='black')\n",
    "#     ax[0].set_title('rPPG Signal - Before Filtering')\n",
    "#     ax[1].plot(preprocessed_signal, color='black')\n",
    "#     ax[1].set_title('rPPG Signal - After Filtering')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-filtered.png\")\n",
    "#     plt.close()\n",
    "            \n",
    "#     ## Compute the Frequency Component (After)\n",
    "#     # Perform FFT on the preprocessed RPPG signal\n",
    "#     fft_result = np.fft.fft(preprocessed_signal)\n",
    "#     fft_freqs = np.fft.fftfreq(len(preprocessed_signal), d=1/fs)\n",
    "\n",
    "#     # Take the magnitude of the FFT result\n",
    "#     fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "#     # Plot the FFT result\n",
    "#     # Plot the FFT result\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "#     plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Magnitude')\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-fft-after.png\")\n",
    "#     plt.close()\n",
    "    \n",
    "#     return preprocessed_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Load the GT and Comparing the Graph -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_gt(folders, preprocessed_signal, image_file):\n",
    "#     target_folders = \"/processed\"\n",
    "\n",
    "#     ## Load the Ground Truth\n",
    "#     gt_path = folders + f\"/vernier/{image_file}_vernier_ecg.csv\"\n",
    "#     gt_ppg = pd.read_csv(gt_path, usecols=[1], header=None).values\n",
    "\n",
    "#     ## Flatten the Signal\n",
    "#     gt_ppg = gt_ppg.flatten()\n",
    "\n",
    "#     ## Downsample to 30Hz\n",
    "#     original_fs = 200\n",
    "#     new_fs = 30\n",
    "\n",
    "#     ## Downsampling the GT PPG Signal\n",
    "#     gt_ppg = scipy.signal.resample(gt_ppg, int(len(gt_ppg) * new_fs / original_fs))\n",
    "\n",
    "#     ## Preprocess the Ground Truth Signal\n",
    "#     gt_ppg = preprocess_ppg(gt_ppg, fs=30)\n",
    "\n",
    "#     ## Show the Filtered GT Signal\n",
    "#     plt.figure(figsize=(20, 5))\n",
    "#     plt.plot(gt_ppg, color='black')\n",
    "#     plt.title('GT Signal - Before Filtering')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-gt.png\")\n",
    "#     plt.close()\n",
    "\n",
    "#     ## Comparing the Signals\n",
    "#     ## Finds the Peaks from the Preprocessed Signal and Ground Truth\n",
    "#     rppg_peaks, _  = scipy.signal.find_peaks(preprocessed_signal)\n",
    "#     gt_peaks, _ = scipy.signal.find_peaks(gt_ppg)\n",
    "\n",
    "#     ## Print the Peaks\n",
    "#     print(f\"Number of Peaks in rPPG Signal: {len(rppg_peaks)}\")\n",
    "#     print(f\"Number of Peaks in Ground Truth: {len(gt_peaks)}\")   \n",
    "\n",
    "#     ## Plot the Signal\n",
    "#     plt.figure(figsize=(20, 5)) \n",
    "#     plt.plot(preprocessed_signal, color='black', label='rPPG Signal')\n",
    "#     plt.plot(rppg_peaks, preprocessed_signal[rppg_peaks], \"x\", color='red', label='rPPG Peaks')\n",
    "#     plt.plot(gt_ppg, color='blue', label='Ground Truth')\n",
    "#     plt.plot(gt_peaks, gt_ppg[gt_peaks], \"x\", color='green', label='Ground Truth Peaks')\n",
    "\n",
    "#     ## Adjust the text position dynamically\n",
    "#     y_max = max(max(preprocessed_signal), max(gt_ppg))  # Get the maximum y-value from both signals\n",
    "#     plt.text(0.02 * len(preprocessed_signal), y_max * 0.9, \n",
    "#             f\"rPPG Peaks: {len(rppg_peaks)}\", color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "#     plt.text(0.02 * len(preprocessed_signal), y_max * 0.8, \n",
    "#             f\"GT Peaks: {len(gt_peaks)}\", color='green', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "#     ## Add title, labels, and legend\n",
    "#     plt.title('rPPG Signal vs Ground Truth')\n",
    "#     plt.xlabel(\"Samples\")\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.legend(['rPPG Signal', 'rPPG Peaks', 'Ground Truth', 'Ground Truth Peaks'])\n",
    "    \n",
    "#     ## Save the graph\n",
    "#     plt.savefig(folders + target_folders + f\"/{image_file}-comparison.png\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## mapping the folders\n",
    "# base_path=f\"../Physio-Itera/Dataset\"\n",
    "\n",
    "# ## Mapping the folders\n",
    "# folders=os.listdir(base_path)\n",
    "\n",
    "# ## Loop the folders /rgb and /vernier\n",
    "# for folder in folders:\n",
    "#     working_folder = base_path + f\"/{folder}\"\n",
    "#     print(working_folder)\n",
    "    \n",
    "#     ## Check if the folder is a directory\n",
    "#     if os.path.isdir(working_folder):\n",
    "#         ## Get the RGB and Vernier Folders as the path\n",
    "\n",
    "#         ## Check if the folder afa\n",
    "#         if folder == \"aqua2\" or folder == :\n",
    "\n",
    "#             subject = folder\n",
    "#             rgb_folder = os.path.join(working_folder, \"rgb\")\n",
    "#             vernier_folder = os.path.join(working_folder, \"vernier\")\n",
    "\n",
    "#             ## Get the video files\n",
    "#             get_image_roi(working_folder, f\"{subject}-roi.png\")\n",
    "\n",
    "#             ## Convert the RPPG \n",
    "#             saving_roi_mediapipe(working_folder, f\"{subject}\")\n",
    "\n",
    "#             ## Getting the pre-processed signal\n",
    "#             preprocessed_signal = processing_signal(working_folder, f\"{subject}\")\n",
    "\n",
    "#             ## Process the Ground Truth\n",
    "#             process_gt(working_folder, preprocessed_signal, f\"{subject}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Preprocessing Stuff\n",
    "Since we have a the raw rppg value of either face landmark / face detection, I think let's vary the pre-processing stuff and see which one better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First case - Ardoni case\n",
    "\n",
    "Using the ardoni case filtering, we use the numpy files from the rppg and load the gt with different pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ppg(signal, fs = 30):\n",
    "    \"\"\" Computes the Preprocessed PPG Signal, this steps include the following:\n",
    "        1. Moving Average Smoothing\n",
    "        2. Bandpass Filtering\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        signal (numpy array): \n",
    "            The PPG Signal to be preprocessed\n",
    "        fs (float): \n",
    "            The Sampling Frequency of the Signal\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy array: \n",
    "            The Preprocessed PPG Signal\n",
    "    \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    # Additional lowpass tod remove high-frequency noise\n",
    "    b, a = scipy.signal.butter(3, [0.9, 2.4], btype='band', fs=fs)\n",
    "    filtered = scipy.signal.filtfilt(b, a, signal)\n",
    "    \n",
    "    # Normalize the signal\n",
    "    normalized_signal = (filtered - np.min(filtered)) / (np.max(filtered) - np.min(filtered))\n",
    "\n",
    "\n",
    "    return normalized_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_signal(folders, image_file, fs=30):\n",
    "    target_folders = \"/processed\" ## Face Detector\n",
    "\n",
    "    export_folders = \"/unos\" ## First Case Export\n",
    "    \n",
    "    if not os.path.exists(folders + export_folders):\n",
    "        os.makedirs(folders + export_folders)\n",
    "\n",
    "    \n",
    "    ## Load the RPPG Signal\n",
    "    rppg_path = folders + target_folders + f\"/{image_file}-rppg.npy\"\n",
    "    rppg_signal = np.load(rppg_path)\n",
    "\n",
    "    ## Compute the Frequency Component (Before)\n",
    "    # Perform FFT on the RPPG signal\n",
    "    fft_result = np.fft.fft(rppg_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(rppg_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-before.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Doing the preprocessing\n",
    "    ## Filter RPPG Signal\n",
    "    preprocessed_signal = preprocess_ppg(rppg_signal, fs=30)\n",
    "\n",
    "    ## Show the Filtered RPPG Signal\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "    ax[0].plot(rppg_signal, color='black')\n",
    "    ax[0].set_title('rPPG Signal - Before Filtering')\n",
    "    ax[1].plot(preprocessed_signal, color='black')\n",
    "    ax[1].set_title('rPPG Signal - After Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-filtered.png\")\n",
    "    plt.close()\n",
    "            \n",
    "    ## Compute the Frequency Component (After)\n",
    "    # Perform FFT on the preprocessed RPPG signal\n",
    "    fft_result = np.fft.fft(preprocessed_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(preprocessed_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-after.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return preprocessed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(folders, preprocessed_signal, image_file):\n",
    "\n",
    "    export_folders = \"/unos\" ## First Case Export       \n",
    "\n",
    "    ## Load the Ground Truth\n",
    "    gt_path = folders + f\"/vernier/{image_file}_vernier_ecg.csv\"\n",
    "    gt_ppg = pd.read_csv(gt_path, usecols=[1], header=None).values\n",
    "\n",
    "    ## Flatten the Signal\n",
    "    gt_ppg = gt_ppg.flatten()\n",
    "\n",
    "    ## Downsample to 30Hz\n",
    "    original_fs = 200\n",
    "    new_fs = 30\n",
    "\n",
    "    ## Downsampling the GT PPG Signal\n",
    "    gt_ppg = scipy.signal.resample(gt_ppg, int(len(gt_ppg) * new_fs / original_fs))\n",
    "\n",
    "    ## Preprocess the Ground Truth Signal\n",
    "    gt_ppg = preprocess_ppg(gt_ppg, fs=30)\n",
    "\n",
    "    ## Show the Filtered GT Signal\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(gt_ppg, color='black')\n",
    "    plt.title('GT Signal - Before Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-gt.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Comparing the Signals\n",
    "    ## Finds the Peaks from the Preprocessed Signal and Ground Truth\n",
    "    rppg_peaks, _  = scipy.signal.find_peaks(preprocessed_signal)\n",
    "    gt_peaks, _ = scipy.signal.find_peaks(gt_ppg)\n",
    "\n",
    "    ## Print the Peaks\n",
    "    print(f\"Number of Peaks in rPPG Signal: {len(rppg_peaks)}\")\n",
    "    print(f\"Number of Peaks in Ground Truth: {len(gt_peaks)}\")   \n",
    "\n",
    "    ## Plot the Signal\n",
    "    plt.figure(figsize=(20, 5)) \n",
    "    plt.plot(preprocessed_signal, color='black', label='rPPG Signal')\n",
    "    plt.plot(rppg_peaks, preprocessed_signal[rppg_peaks], \"x\", color='red', label='rPPG Peaks')\n",
    "    plt.plot(gt_ppg, color='blue', label='Ground Truth')\n",
    "    plt.plot(gt_peaks, gt_ppg[gt_peaks], \"x\", color='green', label='Ground Truth Peaks')\n",
    "\n",
    "    ## Adjust the text position dynamically\n",
    "    y_max = max(max(preprocessed_signal), max(gt_ppg))  # Get the maximum y-value from both signals\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.9, \n",
    "            f\"rPPG Peaks: {len(rppg_peaks)}\", color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.8, \n",
    "            f\"GT Peaks: {len(gt_peaks)}\", color='green', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    ## Add title, labels, and legend\n",
    "    plt.title('rPPG Signal vs Ground Truth')\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend(['rPPG Signal', 'rPPG Peaks', 'Ground Truth', 'Ground Truth Peaks'])\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-comparison.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Physio-Itera/Dataset/ades2\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 88\n",
      "../Physio-Itera/Dataset/ades6\n",
      "Number of Peaks in rPPG Signal: 82\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/adin2\n",
      "Number of Peaks in rPPG Signal: 91\n",
      "Number of Peaks in Ground Truth: 81\n",
      "../Physio-Itera/Dataset/adin6\n",
      "Number of Peaks in rPPG Signal: 92\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/afa2\n",
      "Number of Peaks in rPPG Signal: 103\n",
      "Number of Peaks in Ground Truth: 110\n",
      "../Physio-Itera/Dataset/afa6\n",
      "../Physio-Itera/Dataset/agus2\n",
      "Number of Peaks in rPPG Signal: 111\n",
      "Number of Peaks in Ground Truth: 116\n",
      "../Physio-Itera/Dataset/agus6\n",
      "Number of Peaks in rPPG Signal: 93\n",
      "Number of Peaks in Ground Truth: 106\n",
      "../Physio-Itera/Dataset/aice2\n",
      "Number of Peaks in rPPG Signal: 120\n",
      "Number of Peaks in Ground Truth: 134\n",
      "../Physio-Itera/Dataset/aice6\n",
      "Number of Peaks in rPPG Signal: 99\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alana2\n",
      "Number of Peaks in rPPG Signal: 103\n",
      "Number of Peaks in Ground Truth: 97\n",
      "../Physio-Itera/Dataset/alana6\n",
      "Number of Peaks in rPPG Signal: 91\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alex2\n",
      "Number of Peaks in rPPG Signal: 168\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/alex6\n",
      "Number of Peaks in rPPG Signal: 99\n",
      "Number of Peaks in Ground Truth: 85\n",
      "../Physio-Itera/Dataset/ali2\n",
      "Number of Peaks in rPPG Signal: 95\n",
      "Number of Peaks in Ground Truth: 99\n",
      "../Physio-Itera/Dataset/ali6\n",
      "Number of Peaks in rPPG Signal: 99\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/alina2\n",
      "Number of Peaks in rPPG Signal: 59\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alina6\n",
      "Number of Peaks in rPPG Signal: 82\n",
      "Number of Peaks in Ground Truth: 79\n",
      "../Physio-Itera/Dataset/anggur2\n",
      "Number of Peaks in rPPG Signal: 96\n",
      "Number of Peaks in Ground Truth: 97\n",
      "../Physio-Itera/Dataset/anggur6\n",
      "Number of Peaks in rPPG Signal: 93\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/apu2\n",
      "Number of Peaks in rPPG Signal: 110\n",
      "Number of Peaks in Ground Truth: 112\n",
      "../Physio-Itera/Dataset/apu6\n",
      "Number of Peaks in rPPG Signal: 108\n",
      "Number of Peaks in Ground Truth: 103\n",
      "../Physio-Itera/Dataset/aqua2\n",
      "Number of Peaks in rPPG Signal: 102\n",
      "Number of Peaks in Ground Truth: 103\n",
      "../Physio-Itera/Dataset/aqua6\n",
      "Number of Peaks in rPPG Signal: 96\n",
      "Number of Peaks in Ground Truth: 95\n",
      "../Physio-Itera/Dataset/ara2\n",
      "Number of Peaks in rPPG Signal: 85\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/ara6\n",
      "Number of Peaks in rPPG Signal: 98\n",
      "Number of Peaks in Ground Truth: 81\n",
      "../Physio-Itera/Dataset/arnold2\n",
      "Number of Peaks in rPPG Signal: 101\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/arnold6\n",
      "Number of Peaks in rPPG Signal: 106\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/bunny2\n",
      "Number of Peaks in rPPG Signal: 98\n",
      "Number of Peaks in Ground Truth: 89\n",
      "../Physio-Itera/Dataset/bunny6\n",
      "Number of Peaks in rPPG Signal: 74\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/tryx2\n",
      "Number of Peaks in rPPG Signal: 95\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/tryx6\n",
      "Number of Peaks in rPPG Signal: 102\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/vel2\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/vel6\n",
      "Number of Peaks in rPPG Signal: 83\n",
      "Number of Peaks in Ground Truth: 88\n"
     ]
    }
   ],
   "source": [
    "## mapping the folders\n",
    "base_path=f\"../Physio-Itera/Dataset\"\n",
    "\n",
    "## Mapping the folders\n",
    "folders=os.listdir(base_path)\n",
    "\n",
    "## Loop the folders /rgb and /vernier\n",
    "for folder in folders:\n",
    "    working_folder = base_path + f\"/{folder}\"\n",
    "    print(working_folder)\n",
    "    \n",
    "    ## Check if the folder is a directory\n",
    "    if os.path.isdir(working_folder):\n",
    "        ## Get the RGB and Vernier Folders as the path\n",
    "\n",
    "        ## Check if the folder afa\n",
    "        if folder != \"afa6\":\n",
    "\n",
    "            subject = folder\n",
    "            rgb_folder = os.path.join(working_folder, \"rgb\")\n",
    "            vernier_folder = os.path.join(working_folder, \"vernier\")\n",
    "\n",
    "            ## Getting the pre-processed signal\n",
    "            preprocessed_signal = processing_signal(working_folder, f\"{subject}\")\n",
    "\n",
    "            ## Process the Ground Truth\n",
    "            process_gt(working_folder, preprocessed_signal, f\"{subject}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second case - using Chabysev filtering\n",
    "\n",
    "Using the case filtering, we use the numpy files from the rppg and load the gt with different pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ppg(signal, fs = 30):\n",
    "    \"\"\" Computes the Preprocessed PPG Signal, this steps include the following:\n",
    "        1. Moving Average Smoothing\n",
    "        2. Bandpass Filtering\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        signal (numpy array): \n",
    "            The PPG Signal to be preprocessed\n",
    "        fs (float): \n",
    "            The Sampling Frequency of the Signal\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy array: \n",
    "            The Preprocessed PPG Signal\n",
    "    \n",
    "\n",
    "    \"\"\" \n",
    "    b, a = scipy.signal.cheby2(4, 40, [0.9, 2.4], btype='band', fs=fs)\n",
    "\n",
    "    # Additional lowpass tod remove high-frequency noise\n",
    "    filtered = scipy.signal.filtfilt(b, a, signal)\n",
    "    \n",
    "    # Normalize the signal\n",
    "    normalized_signal = (filtered - np.min(filtered)) / (np.max(filtered) - np.min(filtered))\n",
    "\n",
    "\n",
    "    return normalized_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_signal(folders, image_file, fs=30):\n",
    "    target_folders = \"/processed\" ## Face Detector\n",
    "\n",
    "    export_folders = \"/duos\" ## Second Case Export\n",
    "    \n",
    "    if not os.path.exists(folders + export_folders):\n",
    "        os.makedirs(folders + export_folders)\n",
    "\n",
    "    \n",
    "    ## Load the RPPG Signal\n",
    "    rppg_path = folders + target_folders + f\"/{image_file}-rppg.npy\"\n",
    "    rppg_signal = np.load(rppg_path)\n",
    "\n",
    "    ## Compute the Frequency Component (Before)\n",
    "    # Perform FFT on the RPPG signal\n",
    "    fft_result = np.fft.fft(rppg_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(rppg_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-before.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Doing the preprocessing\n",
    "    ## Filter RPPG Signal\n",
    "    preprocessed_signal = preprocess_ppg(rppg_signal, fs=30)\n",
    "\n",
    "    ## Show the Filtered RPPG Signal\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "    ax[0].plot(rppg_signal, color='black')\n",
    "    ax[0].set_title('rPPG Signal - Before Filtering')\n",
    "    ax[1].plot(preprocessed_signal, color='black')\n",
    "    ax[1].set_title('rPPG Signal - After Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-filtered.png\")\n",
    "    plt.close()\n",
    "            \n",
    "    ## Compute the Frequency Component (After)\n",
    "    # Perform FFT on the preprocessed RPPG signal\n",
    "    fft_result = np.fft.fft(preprocessed_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(preprocessed_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-after.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return preprocessed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(folders, preprocessed_signal, image_file):\n",
    "\n",
    "    export_folders = \"/duos\" ## Second Case Export       \n",
    "\n",
    "    ## Load the Ground Truth\n",
    "    gt_path = folders + f\"/vernier/{image_file}_vernier_ecg.csv\"\n",
    "    gt_ppg = pd.read_csv(gt_path, usecols=[1], header=None).values\n",
    "\n",
    "    ## Flatten the Signal\n",
    "    gt_ppg = gt_ppg.flatten()\n",
    "\n",
    "    ## Downsample to 30Hz\n",
    "    original_fs = 200\n",
    "    new_fs = 30\n",
    "\n",
    "    ## Downsampling the GT PPG Signal\n",
    "    gt_ppg = scipy.signal.resample(gt_ppg, int(len(gt_ppg) * new_fs / original_fs))\n",
    "\n",
    "    ## Preprocess the Ground Truth Signal\n",
    "    gt_ppg = preprocess_ppg(gt_ppg, fs=30)\n",
    "\n",
    "    ## Show the Filtered GT Signal\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(gt_ppg, color='black')\n",
    "    plt.title('GT Signal - Before Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-gt.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Comparing the Signals\n",
    "    ## Finds the Peaks from the Preprocessed Signal and Ground Truth\n",
    "    rppg_peaks, _  = scipy.signal.find_peaks(preprocessed_signal)\n",
    "    gt_peaks, _ = scipy.signal.find_peaks(gt_ppg)\n",
    "\n",
    "    ## Print the Peaks\n",
    "    print(f\"Number of Peaks in rPPG Signal: {len(rppg_peaks)}\")\n",
    "    print(f\"Number of Peaks in Ground Truth: {len(gt_peaks)}\")   \n",
    "\n",
    "    ## Plot the Signal\n",
    "    plt.figure(figsize=(20, 5)) \n",
    "    plt.plot(preprocessed_signal, color='black', label='rPPG Signal')\n",
    "    plt.plot(rppg_peaks, preprocessed_signal[rppg_peaks], \"x\", color='red', label='rPPG Peaks')\n",
    "    plt.plot(gt_ppg, color='blue', label='Ground Truth')\n",
    "    plt.plot(gt_peaks, gt_ppg[gt_peaks], \"x\", color='green', label='Ground Truth Peaks')\n",
    "\n",
    "    ## Adjust the text position dynamically\n",
    "    y_max = max(max(preprocessed_signal), max(gt_ppg))  # Get the maximum y-value from both signals\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.9, \n",
    "            f\"rPPG Peaks: {len(rppg_peaks)}\", color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.8, \n",
    "            f\"GT Peaks: {len(gt_peaks)}\", color='green', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    ## Add title, labels, and legend\n",
    "    plt.title('rPPG Signal vs Ground Truth')\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend(['rPPG Signal', 'rPPG Peaks', 'Ground Truth', 'Ground Truth Peaks'])\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-comparison.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Physio-Itera/Dataset/ades2\n",
      "Number of Peaks in rPPG Signal: 81\n",
      "Number of Peaks in Ground Truth: 88\n",
      "../Physio-Itera/Dataset/ades6\n",
      "Number of Peaks in rPPG Signal: 77\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/adin2\n",
      "Number of Peaks in rPPG Signal: 77\n",
      "Number of Peaks in Ground Truth: 81\n",
      "../Physio-Itera/Dataset/adin6\n",
      "Number of Peaks in rPPG Signal: 78\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/afa2\n",
      "Number of Peaks in rPPG Signal: 97\n",
      "Number of Peaks in Ground Truth: 110\n",
      "../Physio-Itera/Dataset/afa6\n",
      "../Physio-Itera/Dataset/agus2\n",
      "Number of Peaks in rPPG Signal: 99\n",
      "Number of Peaks in Ground Truth: 116\n",
      "../Physio-Itera/Dataset/agus6\n",
      "Number of Peaks in rPPG Signal: 77\n",
      "Number of Peaks in Ground Truth: 106\n",
      "../Physio-Itera/Dataset/aice2\n",
      "Number of Peaks in rPPG Signal: 94\n",
      "Number of Peaks in Ground Truth: 95\n",
      "../Physio-Itera/Dataset/aice6\n",
      "Number of Peaks in rPPG Signal: 83\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/alana2\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 97\n",
      "../Physio-Itera/Dataset/alana6\n",
      "Number of Peaks in rPPG Signal: 85\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alex2\n",
      "Number of Peaks in rPPG Signal: 137\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/alex6\n",
      "Number of Peaks in rPPG Signal: 83\n",
      "Number of Peaks in Ground Truth: 85\n",
      "../Physio-Itera/Dataset/ali2\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 99\n",
      "../Physio-Itera/Dataset/ali6\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/alina2\n",
      "Number of Peaks in rPPG Signal: 53\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alina6\n",
      "Number of Peaks in rPPG Signal: 78\n",
      "Number of Peaks in Ground Truth: 76\n",
      "../Physio-Itera/Dataset/anggur2\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/anggur6\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/apu2\n",
      "Number of Peaks in rPPG Signal: 94\n",
      "Number of Peaks in Ground Truth: 95\n",
      "../Physio-Itera/Dataset/apu6\n",
      "Number of Peaks in rPPG Signal: 95\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/aqua2\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 100\n",
      "../Physio-Itera/Dataset/aqua6\n",
      "Number of Peaks in rPPG Signal: 85\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/ara2\n",
      "Number of Peaks in rPPG Signal: 81\n",
      "Number of Peaks in Ground Truth: 89\n",
      "../Physio-Itera/Dataset/ara6\n",
      "Number of Peaks in rPPG Signal: 84\n",
      "Number of Peaks in Ground Truth: 81\n",
      "../Physio-Itera/Dataset/arnold2\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/arnold6\n",
      "Number of Peaks in rPPG Signal: 91\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/bunny2\n",
      "Number of Peaks in rPPG Signal: 81\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/bunny6\n",
      "Number of Peaks in rPPG Signal: 64\n",
      "Number of Peaks in Ground Truth: 81\n",
      "../Physio-Itera/Dataset/tryx2\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 98\n",
      "../Physio-Itera/Dataset/tryx6\n",
      "Number of Peaks in rPPG Signal: 83\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/vel2\n",
      "Number of Peaks in rPPG Signal: 85\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/vel6\n",
      "Number of Peaks in rPPG Signal: 80\n",
      "Number of Peaks in Ground Truth: 89\n"
     ]
    }
   ],
   "source": [
    "## mapping the folders\n",
    "base_path=f\"../Physio-Itera/Dataset\"\n",
    "\n",
    "## Mapping the folders\n",
    "folders=os.listdir(base_path)\n",
    "\n",
    "## Loop the folders /rgb and /vernier\n",
    "for folder in folders:\n",
    "    working_folder = base_path + f\"/{folder}\"\n",
    "    print(working_folder)\n",
    "    \n",
    "    ## Check if the folder is a directory\n",
    "    if os.path.isdir(working_folder):\n",
    "        ## Get the RGB and Vernier Folders as the path\n",
    "\n",
    "        ## Check if the folder afa\n",
    "        if folder != \"afa6\":\n",
    "\n",
    "            subject = folder\n",
    "            rgb_folder = os.path.join(working_folder, \"rgb\")\n",
    "            vernier_folder = os.path.join(working_folder, \"vernier\")\n",
    "\n",
    "            ## Getting the pre-processed signal\n",
    "            preprocessed_signal = processing_signal(working_folder, f\"{subject}\")\n",
    "\n",
    "            ## Process the Ground Truth\n",
    "            process_gt(working_folder, preprocessed_signal, f\"{subject}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First case - Chabesev v0.2 case\n",
    "\n",
    "Using case filtering, we use the numpy files from the rppg and load the gt with different pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ppg(signal, fs = 30):\n",
    "    \"\"\" Computes the Preprocessed PPG Signal, this steps include the following:\n",
    "        1. Moving Average Smoothing\n",
    "        2. Bandpass Filtering\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        signal (numpy array): \n",
    "            The PPG Signal to be preprocessed\n",
    "        fs (float): \n",
    "            The Sampling Frequency of the Signal\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy array: \n",
    "            The Preprocessed PPG Signal\n",
    "    \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    # Additional lowpass tod remove high-frequency noise\n",
    "    b, a = scipy.signal.cheby2(3, 60, [0.9, 2.4], btype='band', fs=fs)\n",
    "    # b, a = scipy.signal.cheby2(3, 60, [0.8, 2.7], btype='band', fs=fs)\n",
    "\n",
    "    filtered = scipy.signal.filtfilt(b, a, signal)\n",
    "    \n",
    "    # Normalize the signal\n",
    "    normalized_signal = (filtered - np.min(filtered)) / (np.max(filtered) - np.min(filtered))\n",
    "\n",
    "\n",
    "    return normalized_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_signal(folders, image_file, fs=30):\n",
    "    target_folders = \"/processed\" ## Face Detector\n",
    "\n",
    "    export_folders = \"/tres\" ## First Case Export\n",
    "    \n",
    "    if not os.path.exists(folders + export_folders):\n",
    "        os.makedirs(folders + export_folders)\n",
    "\n",
    "    \n",
    "    ## Load the RPPG Signal\n",
    "    rppg_path = folders + target_folders + f\"/{image_file}-rppg.npy\"\n",
    "    rppg_signal = np.load(rppg_path)\n",
    "\n",
    "    ## Compute the Frequency Component (Before)\n",
    "    # Perform FFT on the RPPG signal\n",
    "    fft_result = np.fft.fft(rppg_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(rppg_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-before.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Doing the preprocessing\n",
    "    ## Filter RPPG Signal\n",
    "    preprocessed_signal = preprocess_ppg(rppg_signal, fs=30)\n",
    "\n",
    "    ## Show the Filtered RPPG Signal\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "    ax[0].plot(rppg_signal, color='black')\n",
    "    ax[0].set_title('rPPG Signal - Before Filtering')\n",
    "    ax[1].plot(preprocessed_signal, color='black')\n",
    "    ax[1].set_title('rPPG Signal - After Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-filtered.png\")\n",
    "    plt.close()\n",
    "            \n",
    "    ## Compute the Frequency Component (After)\n",
    "    # Perform FFT on the preprocessed RPPG signal\n",
    "    fft_result = np.fft.fft(preprocessed_signal)\n",
    "    fft_freqs = np.fft.fftfreq(len(preprocessed_signal), d=1/fs)\n",
    "\n",
    "    # Take the magnitude of the FFT result\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "    # Plot the FFT result\n",
    "    # Plot the FFT result\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fft_freqs[:len(fft_freqs)//2], fft_magnitude[:len(fft_magnitude)//2], color='blue')\n",
    "    plt.title('Frequency Spectrum of the RPPG Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-fft-after.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return preprocessed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(folders, preprocessed_signal, image_file):\n",
    "\n",
    "    export_folders = \"/tres\"     \n",
    "\n",
    "    ## Load the Ground Truth\n",
    "    gt_path = folders + f\"/vernier/{image_file}_vernier_ecg.csv\"\n",
    "    gt_ppg = pd.read_csv(gt_path, usecols=[1], header=None).values\n",
    "\n",
    "    ## Flatten the Signal\n",
    "    gt_ppg = gt_ppg.flatten()\n",
    "\n",
    "    ## Downsample to 30Hz\n",
    "    original_fs = 200\n",
    "    new_fs = 30\n",
    "\n",
    "    ## Downsampling the GT PPG Signal\n",
    "    gt_ppg = scipy.signal.resample(gt_ppg, int(len(gt_ppg) * new_fs / original_fs))\n",
    "\n",
    "    ## Preprocess the Ground Truth Signal\n",
    "    gt_ppg = preprocess_ppg(gt_ppg, fs=30)\n",
    "\n",
    "    ## Show the Filtered GT Signal\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(gt_ppg, color='black')\n",
    "    plt.title('GT Signal - Before Filtering')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-gt.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## Comparing the Signals\n",
    "    ## Finds the Peaks from the Preprocessed Signal and Ground Truth\n",
    "    rppg_peaks, _  = scipy.signal.find_peaks(preprocessed_signal)\n",
    "    gt_peaks, _ = scipy.signal.find_peaks(gt_ppg)\n",
    "\n",
    "    ## Print the Peaks\n",
    "    print(f\"Number of Peaks in rPPG Signal: {len(rppg_peaks)}\")\n",
    "    print(f\"Number of Peaks in Ground Truth: {len(gt_peaks)}\")   \n",
    "\n",
    "    ## Plot the Signal\n",
    "    plt.figure(figsize=(20, 5)) \n",
    "    plt.plot(preprocessed_signal, color='black', label='rPPG Signal')\n",
    "    plt.plot(rppg_peaks, preprocessed_signal[rppg_peaks], \"x\", color='red', label='rPPG Peaks')\n",
    "    plt.plot(gt_ppg, color='blue', label='Ground Truth')\n",
    "    plt.plot(gt_peaks, gt_ppg[gt_peaks], \"x\", color='green', label='Ground Truth Peaks')\n",
    "\n",
    "    ## Adjust the text position dynamically\n",
    "    y_max = max(max(preprocessed_signal), max(gt_ppg))  # Get the maximum y-value from both signals\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.9, \n",
    "            f\"rPPG Peaks: {len(rppg_peaks)}\", color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    plt.text(0.02 * len(preprocessed_signal), y_max * 0.8, \n",
    "            f\"GT Peaks: {len(gt_peaks)}\", color='green', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    ## Add title, labels, and legend\n",
    "    plt.title('rPPG Signal vs Ground Truth')\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend(['rPPG Signal', 'rPPG Peaks', 'Ground Truth', 'Ground Truth Peaks'])\n",
    "    \n",
    "    ## Save the graph\n",
    "    plt.savefig(folders + export_folders + f\"/{image_file}-comparison.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Physio-Itera/Dataset/ades2\n",
      "Number of Peaks in rPPG Signal: 85\n",
      "Number of Peaks in Ground Truth: 88\n",
      "../Physio-Itera/Dataset/ades6\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/adin2\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/adin6\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/afa2\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/afa6\n",
      "../Physio-Itera/Dataset/agus2\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/agus6\n",
      "Number of Peaks in rPPG Signal: 76\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/aice2\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 89\n",
      "../Physio-Itera/Dataset/aice6\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 84\n",
      "../Physio-Itera/Dataset/alana2\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/alana6\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/alex2\n",
      "Number of Peaks in rPPG Signal: 140\n",
      "Number of Peaks in Ground Truth: 83\n",
      "../Physio-Itera/Dataset/alex6\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 85\n",
      "../Physio-Itera/Dataset/ali2\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/ali6\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/alina2\n",
      "Number of Peaks in rPPG Signal: 51\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/alina6\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 87\n",
      "../Physio-Itera/Dataset/anggur2\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 94\n",
      "../Physio-Itera/Dataset/anggur6\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 95\n",
      "../Physio-Itera/Dataset/apu2\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/apu6\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/aqua2\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/aqua6\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 93\n",
      "../Physio-Itera/Dataset/ara2\n",
      "Number of Peaks in rPPG Signal: 83\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/ara6\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 82\n",
      "../Physio-Itera/Dataset/arnold2\n",
      "Number of Peaks in rPPG Signal: 90\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/arnold6\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/bunny2\n",
      "Number of Peaks in rPPG Signal: 89\n",
      "Number of Peaks in Ground Truth: 85\n",
      "../Physio-Itera/Dataset/bunny6\n",
      "Number of Peaks in rPPG Signal: 64\n",
      "Number of Peaks in Ground Truth: 86\n",
      "../Physio-Itera/Dataset/tryx2\n",
      "Number of Peaks in rPPG Signal: 88\n",
      "Number of Peaks in Ground Truth: 96\n",
      "../Physio-Itera/Dataset/tryx6\n",
      "Number of Peaks in rPPG Signal: 86\n",
      "Number of Peaks in Ground Truth: 92\n",
      "../Physio-Itera/Dataset/vel2\n",
      "Number of Peaks in rPPG Signal: 87\n",
      "Number of Peaks in Ground Truth: 90\n",
      "../Physio-Itera/Dataset/vel6\n",
      "Number of Peaks in rPPG Signal: 84\n",
      "Number of Peaks in Ground Truth: 88\n"
     ]
    }
   ],
   "source": [
    "## mapping the folders\n",
    "base_path=f\"../Physio-Itera/Dataset\"\n",
    "\n",
    "## Mapping the folders\n",
    "folders=os.listdir(base_path)\n",
    "\n",
    "## Loop the folders /rgb and /vernier\n",
    "for folder in folders:\n",
    "    working_folder = base_path + f\"/{folder}\"\n",
    "    print(working_folder)\n",
    "    \n",
    "    ## Check if the folder is a directory\n",
    "    if os.path.isdir(working_folder):\n",
    "        ## Get the RGB and Vernier Folders as the path\n",
    "\n",
    "        ## Check if the folder afa\n",
    "        if folder != \"afa6\":\n",
    "\n",
    "            subject = folder\n",
    "            rgb_folder = os.path.join(working_folder, \"rgb\")\n",
    "            vernier_folder = os.path.join(working_folder, \"vernier\")\n",
    "\n",
    "            ## Getting the pre-processed signal\n",
    "            preprocessed_signal = processing_signal(working_folder, f\"{subject}\")\n",
    "\n",
    "            ## Process the Ground Truth\n",
    "            process_gt(working_folder, preprocessed_signal, f\"{subject}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codex_astartes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
